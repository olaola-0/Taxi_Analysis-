{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shapefile\n",
    "from sqlalchemy import create_engine\n",
    "import requests\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "from src.paths import TRIP_DATA\n",
    "from src.paths import SQL_DB_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "def download_parquet_files(start_year: int = 2023, start_month: int = 1) -> None:\n",
    "    \"\"\"\n",
    "    Downloads NYC Yellow Taxi trip data parquet files for a specified range of months within the year 2023.\n",
    "\n",
    "    This function iterates through months starting from `start_month` of `start_year` (2023) and\n",
    "    attempts to download the corresponding parquet file if it does not already exist in the storage.\n",
    "    The downloads are limited to the year 2023 to prevent including data from future years.\n",
    "\n",
    "    Parameters:\n",
    "    - start_year (int, optional): The year to start downloading data from, defaults to 2023.\n",
    "    - start_month (int, optional): The month to start downloading data from, defaults to January (1).\n",
    "\n",
    "    Returns:\n",
    "    - None: Files are downloaded to the specified `TRIP_DATA` path, and no value is returned.\n",
    "\n",
    "    Raises:\n",
    "    - Exception: If the file cannot be downloaded due to the URL being unavailable.\n",
    "    \"\"\"\n",
    "    # Set end_year to 2023 to ensure we do not go beyond this year.\n",
    "    end_year = 2023\n",
    "    current_month = datetime.now().month\n",
    "    current_year = datetime.now().year\n",
    "    \n",
    "    # Adjust the range to be within 2023 only, considering the current year and month.\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        for month in range(start_month if year == start_year else 1, \n",
    "                           current_month + 1 if year == current_year and current_year <= end_year else 13):\n",
    "            path = TRIP_DATA / Path(f'rides_{year}_{month:02d}.parquet')\n",
    "            url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{year}-{month:02d}.parquet\"\n",
    "            if not path.exists():\n",
    "                try:\n",
    "                    print(f'Downloading file {year}_{month:02d}')\n",
    "                    r = requests.get(url)\n",
    "                    if r.status_code == 200:\n",
    "                        with open(path, 'wb') as f:\n",
    "                            f.write(r.content)\n",
    "                    else:\n",
    "                        raise Exception(f\"{url} is not available.\")\n",
    "                except Exception as e:\n",
    "                    print(f'Error downloading file for {year}_{month:02d}')\n",
    "                    continue\n",
    "            else:\n",
    "                print(f'File {year}_{month:02d} already in storage.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 2023_01 already in storage.\n",
      "File 2023_02 already in storage.\n",
      "File 2023_03 already in storage.\n",
      "File 2023_04 already in storage.\n",
      "File 2023_05 already in storage.\n",
      "File 2023_06 already in storage.\n",
      "File 2023_07 already in storage.\n",
      "File 2023_08 already in storage.\n",
      "File 2023_09 already in storage.\n",
      "File 2023_10 already in storage.\n",
      "File 2023_11 already in storage.\n",
      "File 2023_12 already in storage.\n"
     ]
    }
   ],
   "source": [
    "# Run the download function.\n",
    "download_parquet_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:32:10</td>\n",
       "      <td>2023-01-01 00:40:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>9.30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:55:08</td>\n",
       "      <td>2023-01-01 01:01:27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>43</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>7.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:25:04</td>\n",
       "      <td>2023-01-01 00:37:49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>48</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>14.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-01 00:03:48</td>\n",
       "      <td>2023-01-01 00:13:25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>12.10</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:10:29</td>\n",
       "      <td>2023-01-01 00:21:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>107</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>11.40</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.68</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066723</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-31 23:58:34</td>\n",
       "      <td>2023-02-01 00:12:33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>107</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>15.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066724</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-31 23:31:09</td>\n",
       "      <td>2023-01-31 23:50:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>112</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>22.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066725</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-31 23:01:05</td>\n",
       "      <td>2023-01-31 23:25:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>114</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>17.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066726</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-31 23:40:00</td>\n",
       "      <td>2023-01-31 23:53:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>230</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>18.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066727</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-31 23:07:32</td>\n",
       "      <td>2023-01-31 23:21:56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>262</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>15.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3066728 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0               2  2023-01-01 00:32:10   2023-01-01 00:40:36              1.0   \n",
       "1               2  2023-01-01 00:55:08   2023-01-01 01:01:27              1.0   \n",
       "2               2  2023-01-01 00:25:04   2023-01-01 00:37:49              1.0   \n",
       "3               1  2023-01-01 00:03:48   2023-01-01 00:13:25              0.0   \n",
       "4               2  2023-01-01 00:10:29   2023-01-01 00:21:19              1.0   \n",
       "...           ...                  ...                   ...              ...   \n",
       "3066723         2  2023-01-31 23:58:34   2023-02-01 00:12:33              NaN   \n",
       "3066724         2  2023-01-31 23:31:09   2023-01-31 23:50:36              NaN   \n",
       "3066725         2  2023-01-31 23:01:05   2023-01-31 23:25:36              NaN   \n",
       "3066726         2  2023-01-31 23:40:00   2023-01-31 23:53:00              NaN   \n",
       "3066727         2  2023-01-31 23:07:32   2023-01-31 23:21:56              NaN   \n",
       "\n",
       "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
       "0                 0.97         1.0                  N           161   \n",
       "1                 1.10         1.0                  N            43   \n",
       "2                 2.51         1.0                  N            48   \n",
       "3                 1.90         1.0                  N           138   \n",
       "4                 1.43         1.0                  N           107   \n",
       "...                ...         ...                ...           ...   \n",
       "3066723           3.05         NaN               None           107   \n",
       "3066724           5.80         NaN               None           112   \n",
       "3066725           4.67         NaN               None           114   \n",
       "3066726           3.15         NaN               None           230   \n",
       "3066727           2.85         NaN               None           262   \n",
       "\n",
       "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0                 141             2         9.30   1.00      0.5        0.00   \n",
       "1                 237             1         7.90   1.00      0.5        4.00   \n",
       "2                 238             1        14.90   1.00      0.5       15.00   \n",
       "3                   7             1        12.10   7.25      0.5        0.00   \n",
       "4                  79             1        11.40   1.00      0.5        3.28   \n",
       "...               ...           ...          ...    ...      ...         ...   \n",
       "3066723            48             0        15.80   0.00      0.5        3.96   \n",
       "3066724            75             0        22.43   0.00      0.5        2.64   \n",
       "3066725           239             0        17.61   0.00      0.5        5.32   \n",
       "3066726            79             0        18.15   0.00      0.5        4.43   \n",
       "3066727           143             0        15.97   0.00      0.5        2.00   \n",
       "\n",
       "         tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0                 0.0                    1.0         14.30   \n",
       "1                 0.0                    1.0         16.90   \n",
       "2                 0.0                    1.0         34.90   \n",
       "3                 0.0                    1.0         20.85   \n",
       "4                 0.0                    1.0         19.68   \n",
       "...               ...                    ...           ...   \n",
       "3066723           0.0                    1.0         23.76   \n",
       "3066724           0.0                    1.0         29.07   \n",
       "3066725           0.0                    1.0         26.93   \n",
       "3066726           0.0                    1.0         26.58   \n",
       "3066727           0.0                    1.0         21.97   \n",
       "\n",
       "         congestion_surcharge  airport_fee  \n",
       "0                         2.5         0.00  \n",
       "1                         2.5         0.00  \n",
       "2                         2.5         0.00  \n",
       "3                         0.0         1.25  \n",
       "4                         2.5         0.00  \n",
       "...                       ...          ...  \n",
       "3066723                   NaN          NaN  \n",
       "3066724                   NaN          NaN  \n",
       "3066725                   NaN          NaN  \n",
       "3066726                   NaN          NaN  \n",
       "3066727                   NaN          NaN  \n",
       "\n",
       "[3066728 rows x 19 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_parquet(TRIP_DATA/f'rides_2023_01.parquet')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def validate_and_clean_data(file_paths: List[Path], start_datetime: str, end_datetime: str) -> None:\n",
    "    \"\"\"\n",
    "    Validates and cleans NYC Yellow Taxi trip data by removing rows with pickup_datetime values\n",
    "    outside the specified valid range.\n",
    "\n",
    "    Parameters:\n",
    "    - file_paths (List[Path]): A list of Paths to the .parquet files to be processed.\n",
    "    - start_datetime (str): The start of the valid datetime range in 'YYYY-MM-DD HH:MM:SS' format.\n",
    "    - end_datetime (str): The end of the valid datetime range in 'YYYY-MM-DD HH:MM:SS' format.\n",
    "\n",
    "    Returns:\n",
    "    - None: The function directly modifies the files on disk, removing invalid rows.\n",
    "\n",
    "    Note: This function assumes the 'tpep_pickup_datetime' column is in the correct datetime format. Adjust\n",
    "    the date parsing as necessary based on the actual data format.\n",
    "    \"\"\"\n",
    "    for file_path in file_paths:\n",
    "        # Read the parquet file\n",
    "        df = pd.read_parquet(file_path)\n",
    "\n",
    "        # Convert 'pickup_datetime' column to datetime if not already\n",
    "        df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "\n",
    "        # Filter the DataFrame based on the valid datetime range\n",
    "        valid_data = df[(df['tpep_pickup_datetime'] >= start_datetime) & (df['tpep_pickup_datetime'] <= end_datetime)]\n",
    "\n",
    "        # Save the cleaned data back to disk, overwriting the original file\n",
    "        valid_data.to_parquet(file_path, index=False)\n",
    "\n",
    "        print(f\"Processed and cleaned data in {file_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and cleaned data in /Users/olanrewajuoladele/Desktop/nyc_taxi_analysis/data/trip_data/rides_2023_01.parquet.\n",
      "Processed and cleaned data in /Users/olanrewajuoladele/Desktop/nyc_taxi_analysis/data/trip_data/rides_2023_02.parquet.\n",
      "Processed and cleaned data in /Users/olanrewajuoladele/Desktop/nyc_taxi_analysis/data/trip_data/rides_2023_03.parquet.\n",
      "Processed and cleaned data in /Users/olanrewajuoladele/Desktop/nyc_taxi_analysis/data/trip_data/rides_2023_04.parquet.\n",
      "Processed and cleaned data in /Users/olanrewajuoladele/Desktop/nyc_taxi_analysis/data/trip_data/rides_2023_05.parquet.\n",
      "Processed and cleaned data in /Users/olanrewajuoladele/Desktop/nyc_taxi_analysis/data/trip_data/rides_2023_06.parquet.\n",
      "Processed and cleaned data in /Users/olanrewajuoladele/Desktop/nyc_taxi_analysis/data/trip_data/rides_2023_07.parquet.\n",
      "Processed and cleaned data in /Users/olanrewajuoladele/Desktop/nyc_taxi_analysis/data/trip_data/rides_2023_08.parquet.\n",
      "Processed and cleaned data in /Users/olanrewajuoladele/Desktop/nyc_taxi_analysis/data/trip_data/rides_2023_09.parquet.\n",
      "Processed and cleaned data in /Users/olanrewajuoladele/Desktop/nyc_taxi_analysis/data/trip_data/rides_2023_10.parquet.\n",
      "Processed and cleaned data in /Users/olanrewajuoladele/Desktop/nyc_taxi_analysis/data/trip_data/rides_2023_11.parquet.\n",
      "Processed and cleaned data in /Users/olanrewajuoladele/Desktop/nyc_taxi_analysis/data/trip_data/rides_2023_12.parquet.\n"
     ]
    }
   ],
   "source": [
    "file_paths =[TRIP_DATA/f'rides_2023_{month:02d}.parquet' for month in range(1, 13)]\n",
    "\n",
    "# Define the valid datetime range\n",
    "start_datetime = '2023-01-01 00:00:00'\n",
    "end_datetime = '2023-12-31 23:59:59'\n",
    "\n",
    "validate_and_clean_data(file_paths=file_paths,\n",
    "                        start_datetime=start_datetime,\n",
    "                        end_datetime=end_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the engine with the path to the nyc_taxi_data.db file in the database folder\n",
    "engine = create_engine(f'sqlite:///{SQL_DB_DIR}/nyc_taxi_data.db')\n",
    "\n",
    "def load_data_to_sqlite():\n",
    "    \"\"\"\n",
    "    Loads NYC Yellow Taxi data from .parquet files into an SQLite database.\n",
    "\n",
    "    Iterates through .parquet files starting from January for each year including and following 2023,\n",
    "    reading each file into a pandas DataFrame and appending it to the 'yellow_taxi_data' table in\n",
    "    the specified SQLite database. This process is repeated for each month up to the current month in the current year.\n",
    "\n",
    "    Note: Ensure the SQL_DB_DIR variable is correctly set to the directory containing the SQLite database.\n",
    "    \"\"\"\n",
    "    current_month = datetime.now().month\n",
    "    current_year = datetime.now().year\n",
    "    for year in range(2023, current_year + 1):\n",
    "        for month in range(1, current_month + 1 if year == current_year else 13):\n",
    "            file_name = f\"rides_{year}_{month:02d}.parquet\"\n",
    "            try:\n",
    "                # Update TRIP_DATA to the correct path where your parquet files are stored\n",
    "                df = pd.read_parquet(TRIP_DATA / file_name)\n",
    "                df.to_sql('yellow_taxi_data', engine, if_exists='append', index=False)\n",
    "                print(f\"Loaded {file_name} into SQLite database.\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(f\"Failed to load {file_name}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rides_2023_01.parquet into SQLite database.\n",
      "Loaded rides_2023_02.parquet into SQLite database.\n",
      "Loaded rides_2023_03.parquet into SQLite database.\n",
      "Loaded rides_2023_04.parquet into SQLite database.\n",
      "Loaded rides_2023_05.parquet into SQLite database.\n",
      "Loaded rides_2023_06.parquet into SQLite database.\n",
      "Loaded rides_2023_07.parquet into SQLite database.\n",
      "Loaded rides_2023_08.parquet into SQLite database.\n",
      "Loaded rides_2023_09.parquet into SQLite database.\n",
      "Loaded rides_2023_10.parquet into SQLite database.\n",
      "Loaded rides_2023_11.parquet into SQLite database.\n",
      "Loaded rides_2023_12.parquet into SQLite database.\n",
      "[Errno 2] No such file or directory: '/Users/olanrewajuoladele/Desktop/nyc_taxi_analysis/data/trip_data/rides_2024_01.parquet'\n",
      "Failed to load rides_2024_01.parquet.\n",
      "[Errno 2] No such file or directory: '/Users/olanrewajuoladele/Desktop/nyc_taxi_analysis/data/trip_data/rides_2024_02.parquet'\n",
      "Failed to load rides_2024_02.parquet.\n",
      "[Errno 2] No such file or directory: '/Users/olanrewajuoladele/Desktop/nyc_taxi_analysis/data/trip_data/rides_2024_03.parquet'\n",
      "Failed to load rides_2024_03.parquet.\n",
      "[Errno 2] No such file or directory: '/Users/olanrewajuoladele/Desktop/nyc_taxi_analysis/data/trip_data/rides_2024_04.parquet'\n",
      "Failed to load rides_2024_04.parquet.\n"
     ]
    }
   ],
   "source": [
    "# Running the function to load data into SQLite.\n",
    "load_data_to_sqlite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.paths import TAXI_ZONES_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download successful.\n",
      "Extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# URL from where to download the ZIP file\n",
    "url = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi_zones.zip\"\n",
    "\n",
    "# Define the local path where the ZIP file will be saved\n",
    "# TAXI_ZONES_DIR is a Path object pointing to the desired directory\n",
    "local_zip_path = TAXI_ZONES_DIR / \"taxi_zones.zip\"\n",
    "\n",
    "# Define the folder where to extract the contents of the ZIP file\n",
    "# Here, we're extracting directly into the TAXI_ZONES_DIR\n",
    "extract_to_folder = TAXI_ZONES_DIR\n",
    "\n",
    "# Start the download\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    with open(local_zip_path, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    print(\"Download successful.\")\n",
    "else:\n",
    "    print(f\"Failed to download file. Status code: {response.status_code}\")\n",
    "\n",
    "# Extract the ZIP file\n",
    "try:\n",
    "    with zipfile.ZipFile(local_zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extract_to_folder)\n",
    "    print(\"Extraction complete.\")\n",
    "except zipfile.BadZipFile:\n",
    "    print(\"Error: The downloaded file is not a valid ZIP file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read the shapefile.\n",
      "Shapes: [Shape #0: POLYGON, Shape #1: POLYGON, Shape #2: POLYGON, Shape #3: POLYGON, Shape #4: POLYGON, Shape #5: POLYGON, Shape #6: POLYGON, Shape #7: POLYGON, Shape #8: POLYGON, Shape #9: POLYGON, Shape #10: POLYGON, Shape #11: POLYGON, Shape #12: POLYGON, Shape #13: POLYGON, Shape #14: POLYGON, Shape #15: POLYGON, Shape #16: POLYGON, Shape #17: POLYGON, Shape #18: POLYGON, Shape #19: POLYGON, Shape #20: POLYGON, Shape #21: POLYGON, Shape #22: POLYGON, Shape #23: POLYGON, Shape #24: POLYGON, Shape #25: POLYGON, Shape #26: POLYGON, Shape #27: POLYGON, Shape #28: POLYGON, Shape #29: POLYGON, Shape #30: POLYGON, Shape #31: POLYGON, Shape #32: POLYGON, Shape #33: POLYGON, Shape #34: POLYGON, Shape #35: POLYGON, Shape #36: POLYGON, Shape #37: POLYGON, Shape #38: POLYGON, Shape #39: POLYGON, Shape #40: POLYGON, Shape #41: POLYGON, Shape #42: POLYGON, Shape #43: POLYGON, Shape #44: POLYGON, Shape #45: POLYGON, Shape #46: POLYGON, Shape #47: POLYGON, Shape #48: POLYGON, Shape #49: POLYGON, Shape #50: POLYGON, Shape #51: POLYGON, Shape #52: POLYGON, Shape #53: POLYGON, Shape #54: POLYGON, Shape #55: POLYGON, Shape #56: POLYGON, Shape #57: POLYGON, Shape #58: POLYGON, Shape #59: POLYGON, Shape #60: POLYGON, Shape #61: POLYGON, Shape #62: POLYGON, Shape #63: POLYGON, Shape #64: POLYGON, Shape #65: POLYGON, Shape #66: POLYGON, Shape #67: POLYGON, Shape #68: POLYGON, Shape #69: POLYGON, Shape #70: POLYGON, Shape #71: POLYGON, Shape #72: POLYGON, Shape #73: POLYGON, Shape #74: POLYGON, Shape #75: POLYGON, Shape #76: POLYGON, Shape #77: POLYGON, Shape #78: POLYGON, Shape #79: POLYGON, Shape #80: POLYGON, Shape #81: POLYGON, Shape #82: POLYGON, Shape #83: POLYGON, Shape #84: POLYGON, Shape #85: POLYGON, Shape #86: POLYGON, Shape #87: POLYGON, Shape #88: POLYGON, Shape #89: POLYGON, Shape #90: POLYGON, Shape #91: POLYGON, Shape #92: POLYGON, Shape #93: POLYGON, Shape #94: POLYGON, Shape #95: POLYGON, Shape #96: POLYGON, Shape #97: POLYGON, Shape #98: POLYGON, Shape #99: POLYGON, Shape #100: POLYGON, Shape #101: POLYGON, Shape #102: POLYGON, Shape #103: POLYGON, Shape #104: POLYGON, Shape #105: POLYGON, Shape #106: POLYGON, Shape #107: POLYGON, Shape #108: POLYGON, Shape #109: POLYGON, Shape #110: POLYGON, Shape #111: POLYGON, Shape #112: POLYGON, Shape #113: POLYGON, Shape #114: POLYGON, Shape #115: POLYGON, Shape #116: POLYGON, Shape #117: POLYGON, Shape #118: POLYGON, Shape #119: POLYGON, Shape #120: POLYGON, Shape #121: POLYGON, Shape #122: POLYGON, Shape #123: POLYGON, Shape #124: POLYGON, Shape #125: POLYGON, Shape #126: POLYGON, Shape #127: POLYGON, Shape #128: POLYGON, Shape #129: POLYGON, Shape #130: POLYGON, Shape #131: POLYGON, Shape #132: POLYGON, Shape #133: POLYGON, Shape #134: POLYGON, Shape #135: POLYGON, Shape #136: POLYGON, Shape #137: POLYGON, Shape #138: POLYGON, Shape #139: POLYGON, Shape #140: POLYGON, Shape #141: POLYGON, Shape #142: POLYGON, Shape #143: POLYGON, Shape #144: POLYGON, Shape #145: POLYGON, Shape #146: POLYGON, Shape #147: POLYGON, Shape #148: POLYGON, Shape #149: POLYGON, Shape #150: POLYGON, Shape #151: POLYGON, Shape #152: POLYGON, Shape #153: POLYGON, Shape #154: POLYGON, Shape #155: POLYGON, Shape #156: POLYGON, Shape #157: POLYGON, Shape #158: POLYGON, Shape #159: POLYGON, Shape #160: POLYGON, Shape #161: POLYGON, Shape #162: POLYGON, Shape #163: POLYGON, Shape #164: POLYGON, Shape #165: POLYGON, Shape #166: POLYGON, Shape #167: POLYGON, Shape #168: POLYGON, Shape #169: POLYGON, Shape #170: POLYGON, Shape #171: POLYGON, Shape #172: POLYGON, Shape #173: POLYGON, Shape #174: POLYGON, Shape #175: POLYGON, Shape #176: POLYGON, Shape #177: POLYGON, Shape #178: POLYGON, Shape #179: POLYGON, Shape #180: POLYGON, Shape #181: POLYGON, Shape #182: POLYGON, Shape #183: POLYGON, Shape #184: POLYGON, Shape #185: POLYGON, Shape #186: POLYGON, Shape #187: POLYGON, Shape #188: POLYGON, Shape #189: POLYGON, Shape #190: POLYGON, Shape #191: POLYGON, Shape #192: POLYGON, Shape #193: POLYGON, Shape #194: POLYGON, Shape #195: POLYGON, Shape #196: POLYGON, Shape #197: POLYGON, Shape #198: POLYGON, Shape #199: POLYGON, Shape #200: POLYGON, Shape #201: POLYGON, Shape #202: POLYGON, Shape #203: POLYGON, Shape #204: POLYGON, Shape #205: POLYGON, Shape #206: POLYGON, Shape #207: POLYGON, Shape #208: POLYGON, Shape #209: POLYGON, Shape #210: POLYGON, Shape #211: POLYGON, Shape #212: POLYGON, Shape #213: POLYGON, Shape #214: POLYGON, Shape #215: POLYGON, Shape #216: POLYGON, Shape #217: POLYGON, Shape #218: POLYGON, Shape #219: POLYGON, Shape #220: POLYGON, Shape #221: POLYGON, Shape #222: POLYGON, Shape #223: POLYGON, Shape #224: POLYGON, Shape #225: POLYGON, Shape #226: POLYGON, Shape #227: POLYGON, Shape #228: POLYGON, Shape #229: POLYGON, Shape #230: POLYGON, Shape #231: POLYGON, Shape #232: POLYGON, Shape #233: POLYGON, Shape #234: POLYGON, Shape #235: POLYGON, Shape #236: POLYGON, Shape #237: POLYGON, Shape #238: POLYGON, Shape #239: POLYGON, Shape #240: POLYGON, Shape #241: POLYGON, Shape #242: POLYGON, Shape #243: POLYGON, Shape #244: POLYGON, Shape #245: POLYGON, Shape #246: POLYGON, Shape #247: POLYGON, Shape #248: POLYGON, Shape #249: POLYGON, Shape #250: POLYGON, Shape #251: POLYGON, Shape #252: POLYGON, Shape #253: POLYGON, Shape #254: POLYGON, Shape #255: POLYGON, Shape #256: POLYGON, Shape #257: POLYGON, Shape #258: POLYGON, Shape #259: POLYGON, Shape #260: POLYGON, Shape #261: POLYGON, Shape #262: POLYGON]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Read the .shp file from the 'TAXI_ZONES_DIR'\n",
    "    sf = shapefile.Reader(TAXI_ZONES_DIR/'taxi_zones.shp')\n",
    "    print(\"Successfully read the shapefile.\")\n",
    "    # Optional: Print out the shapes or records to confirm\n",
    "    print(sf.shapes())\n",
    "except Exception as e:\n",
    "    print(\"Failed to read the shapefile:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields in the shapefile:\n",
      "['OBJECTID', 'N', 9, 0]\n",
      "['Shape_Leng', 'F', 19, 11]\n",
      "['Shape_Area', 'F', 19, 11]\n",
      "['zone', 'C', 254, 0]\n",
      "['LocationID', 'N', 4, 0]\n",
      "['borough', 'C', 254, 0]\n"
     ]
    }
   ],
   "source": [
    "fields = sf.fields\n",
    "# Printing the fields\n",
    "print(\"Fields in the shapefile:\")\n",
    "for field in fields[1:]:  # Skip the first element as it's a deletion flag field\n",
    "    print(field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "from shapely.geometry import shape\n",
    "\n",
    "def calculate_centroids(filepath: str) -> list:\n",
    "    \"\"\"\n",
    "    Calculates the centroids of geographic features from a shapefile.\n",
    "\n",
    "    This function opens a shapefile specified by the filepath, iterates through each geographic\n",
    "    feature, calculates the centroid of the feature, and collects the centroid's coordinates\n",
    "    along with the feature's LocationID. It returns a list of dictionaries, each containing\n",
    "    the LocationID, latitude, and longitude of a feature's centroid.\n",
    "\n",
    "    Parameters:\n",
    "    - filepath (str): The path to the shapefile from which to read the geographic features.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of dictionaries. Each dictionary represents a feature's centroid and contains\n",
    "      'LocationID', 'Latitude', and 'Longitude' keys.\n",
    "    \n",
    "    Example of returned list item:\n",
    "    - {'LocationID': '1', 'Latitude': 40.123456, 'Longitude': -74.123456}\n",
    "    \n",
    "    Note:\n",
    "    This function relies on Fiona to read shapefiles and Shapely to calculate geometric properties.\n",
    "    Ensure these libraries are installed and the shapefile contains a 'LocationID' field.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize a list to hold centroid information\n",
    "    centroids = []\n",
    "\n",
    "    # Use Fiona to open the shapefile\n",
    "    with fiona.open(filepath, 'r') as shp:\n",
    "        # Iterate over each feature in the shapefile\n",
    "        for item in shp:\n",
    "            # Convert the geometry part of the feature into a Shapely Geometry object\n",
    "            geom = shape(item['geometry'])\n",
    "            \n",
    "            # Calculate the centroid of the geometry\n",
    "            centroid = geom.centroid\n",
    "            \n",
    "            # Append a dictionary with LocationID, latitude, and longitude of the centroid\n",
    "            centroids.append({\n",
    "                'LocationID': item['properties']['LocationID'],  # Extract LocationID from feature properties\n",
    "                'Latitude': centroid.y,  # Latitude (y coordinate) of the centroid\n",
    "                'Longitude': centroid.x  # Longitude (x coordinate) of the centroid\n",
    "            })\n",
    "\n",
    "    # Return the list of centroids\n",
    "    return centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>191376.749531</td>\n",
       "      <td>9.359968e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>164018.754403</td>\n",
       "      <td>1.031086e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>254265.478659</td>\n",
       "      <td>1.026453e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>202959.782391</td>\n",
       "      <td>9.906340e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>140681.351376</td>\n",
       "      <td>9.318714e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LocationID       Latitude     Longitude\n",
       "0           1  191376.749531  9.359968e+05\n",
       "1           2  164018.754403  1.031086e+06\n",
       "2           3  254265.478659  1.026453e+06\n",
       "3           4  202959.782391  9.906340e+05\n",
       "4           5  140681.351376  9.318714e+05"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate centroids for the taxi_zones shapefile\n",
    "centroids_data = calculate_centroids(TAXI_ZONES_DIR/'taxi_zones.shp')\n",
    "\n",
    "# Convert the list of centroids to a DataFrame\n",
    "centroids_df = pd.DataFrame(centroids_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "centroids_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing LocationID: {104, 57, 105}\n"
     ]
    }
   ],
   "source": [
    "# Check for missing LocationID.\n",
    "expected_ids = set(range(1, 264))\n",
    "actual_ids = set(centroids_df['LocationID'].unique())\n",
    "missing_ids = expected_ids - actual_ids\n",
    "\n",
    "print(f\"Missing LocationID: {missing_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Transformer\n",
    "\n",
    "def calculate_transformed_centroids(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates and transforms the centroids of geographic features from a shapefile\n",
    "    to WGS 84 (EPSG:4326) coordinate reference system and returns them as a pandas DataFrame.\n",
    "\n",
    "    This function opens a shapefile, iterates through each geographic feature to calculate\n",
    "    the centroid, transforms the centroid coordinates from the source CRS (EPSG:2263 by default)\n",
    "    to WGS 84 (EPSG:4326), and collects these transformed coordinates along with the feature's\n",
    "    LocationID. The results are returned in a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - filepath (str): The path to the shapefile from which to read the geographic features.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with columns 'LocationID', 'Latitude', and 'Longitude'\n",
    "      for each feature's centroid in WGS 84 coordinates.\n",
    "    \n",
    "    Note:\n",
    "    - This function assumes the shapefile uses the EPSG:2263 (NAD83/New York Long Island) CRS.\n",
    "      If your data uses a different source CRS, adjust the `from_crs` parameter of the Transformer accordingly.\n",
    "    - The function relies on Fiona for reading shapefiles, Shapely for geometric operations,\n",
    "      PyProj for CRS transformation, and pandas for data structuring. Ensure these libraries are installed.\n",
    "    \"\"\"\n",
    "    # Initialize a transformer to convert from EPSG:2263 to EPSG:4326, ensuring longitude comes before latitude\n",
    "    transformer = Transformer.from_crs(\"epsg:2263\", \"epsg:4326\", always_xy=True)\n",
    "    \n",
    "    centroids = []  # List to store centroid information\n",
    "    with fiona.open(filepath, 'r') as shp:  # Open the shapefile\n",
    "        for item in shp:  # Iterate over each feature\n",
    "            geom = shape(item['geometry'])  # Convert geometry to Shapely object\n",
    "            centroid = geom.centroid  # Calculate centroid\n",
    "            # Transform the centroid coordinates to WGS 84\n",
    "            lon, lat = transformer.transform(centroid.x, centroid.y)\n",
    "            # Append the transformed coordinates with LocationID to the list\n",
    "            centroids.append({\n",
    "                'LocationID': item['properties']['LocationID'],  # LocationID from feature properties\n",
    "                'Latitude': lat,  # Transformed latitude\n",
    "                'Longitude': lon  # Transformed longitude\n",
    "            })\n",
    "    \n",
    "    # Convert the list of centroids to a pandas DataFrame and return\n",
    "    return pd.DataFrame(centroids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>40.691830</td>\n",
       "      <td>-74.174002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>40.616746</td>\n",
       "      <td>-73.831300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>40.864474</td>\n",
       "      <td>-73.847422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>40.723752</td>\n",
       "      <td>-73.976968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>40.552659</td>\n",
       "      <td>-74.188485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LocationID   Latitude  Longitude\n",
       "0           1  40.691830 -74.174002\n",
       "1           2  40.616746 -73.831300\n",
       "2           3  40.864474 -73.847422\n",
       "3           4  40.723752 -73.976968\n",
       "4           5  40.552659 -74.188485"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate and transform centroids\n",
    "transformed_centroids_df = calculate_transformed_centroids(TAXI_ZONES_DIR/'taxi_zones.shp')\n",
    "\n",
    "# Display the DataFrame\n",
    "transformed_centroids_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     LocationID   Latitude  Longitude\n",
      "55           56  40.741407 -73.858845\n",
      "56           56  40.751819 -73.853582\n",
      "102         103  40.689860 -74.045288\n",
      "103         103  40.698769 -74.040771\n",
      "104         103  40.688784 -74.019073\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates based on 'LocationID'\n",
    "duplicates = transformed_centroids_df[transformed_centroids_df.duplicated('LocationID', keep=False)]\n",
    "\n",
    "# Print out the duplicates\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102, 103, 104]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Replace the second occurrence of '56' with '57'\n",
    "# Convert LocationID column to a list for manipulation\n",
    "location_ids = transformed_centroids_df['LocationID'].tolist()\n",
    "second_occurrence_index = [index for index, value in enumerate(location_ids) if value == 56][1]\n",
    "transformed_centroids_df.at[second_occurrence_index, 'LocationID'] = 57\n",
    "\n",
    "# Step 2:Replace the second and third occurence of '103 with '104 nd 105' respectively.\n",
    "occurrences_103_indices = [index for index, value in enumerate(location_ids) if value == 103]\n",
    "print(occurrences_103_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     LocationID   Latitude  Longitude\n",
      "101         102  40.703546 -73.875737\n",
      "102         103  40.689860 -74.045288\n",
      "103         104  40.698769 -74.040771\n",
      "104         105  40.688784 -74.019073\n",
      "105         106  40.673513 -73.990648\n"
     ]
    }
   ],
   "source": [
    "# Safety check to ensure there are at least three occurrences\n",
    "if len(occurrences_103_indices) >= 3:\n",
    "    # Step 2: Update the second and third occurrences of '103' to '104' and '105'\n",
    "    transformed_centroids_df.at[occurrences_103_indices[1], 'LocationID'] = 104\n",
    "    transformed_centroids_df.at[occurrences_103_indices[2], 'LocationID'] = 105\n",
    "else:\n",
    "    print(\"Not enough occurrences of '103' to update.\")\n",
    "\n",
    "print(transformed_centroids_df.loc[transformed_centroids_df['LocationID'].isin([102, 103, 104, 105, 106])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_centroids_df.LocationID.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract field names directly, skipping the first 'DeletionFlag' field\n",
    "fields_name = [field[0] for field in sf.fields[1:]]\n",
    "\n",
    "attributes = [dict(zip(fields_name, attr)) for attr in sf.records()]\n",
    "\n",
    "# Create a DataFrame directly from the list of attribute dictionaries\n",
    "df_attributes = pd.DataFrame(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_location = pd.merge(df_attributes, transformed_centroids_df, on='LocationID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>zone</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>borough</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.116357</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>40.691830</td>\n",
       "      <td>-74.174002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.433470</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>40.616746</td>\n",
       "      <td>-73.831300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.084341</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>40.864474</td>\n",
       "      <td>-73.847422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>40.723752</td>\n",
       "      <td>-73.976968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.092146</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>40.552659</td>\n",
       "      <td>-74.188485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  Shape_Leng  Shape_Area                     zone  LocationID  \\\n",
       "0         1    0.116357    0.000782           Newark Airport           1   \n",
       "1         2    0.433470    0.004866              Jamaica Bay           2   \n",
       "2         3    0.084341    0.000314  Allerton/Pelham Gardens           3   \n",
       "3         4    0.043567    0.000112            Alphabet City           4   \n",
       "4         5    0.092146    0.000498            Arden Heights           5   \n",
       "\n",
       "         borough   Latitude  Longitude  \n",
       "0            EWR  40.691830 -74.174002  \n",
       "1         Queens  40.616746 -73.831300  \n",
       "2          Bronx  40.864474 -73.847422  \n",
       "3      Manhattan  40.723752 -73.976968  \n",
       "4  Staten Island  40.552659 -74.188485  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_location.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>zone</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>borough</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>259</td>\n",
       "      <td>0.126750</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>Woodlawn/Wakefield</td>\n",
       "      <td>259</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>40.897932</td>\n",
       "      <td>-73.852215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>260</td>\n",
       "      <td>0.133514</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>Woodside</td>\n",
       "      <td>260</td>\n",
       "      <td>Queens</td>\n",
       "      <td>40.744234</td>\n",
       "      <td>-73.906307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>261</td>\n",
       "      <td>0.027120</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>World Trade Center</td>\n",
       "      <td>261</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>40.709139</td>\n",
       "      <td>-74.013023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>262</td>\n",
       "      <td>0.049064</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>Yorkville East</td>\n",
       "      <td>262</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>40.775932</td>\n",
       "      <td>-73.946510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>263</td>\n",
       "      <td>0.037017</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>263</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>40.778766</td>\n",
       "      <td>-73.951010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     OBJECTID  Shape_Leng  Shape_Area                zone  LocationID  \\\n",
       "258       259    0.126750    0.000395  Woodlawn/Wakefield         259   \n",
       "259       260    0.133514    0.000422            Woodside         260   \n",
       "260       261    0.027120    0.000034  World Trade Center         261   \n",
       "261       262    0.049064    0.000122      Yorkville East         262   \n",
       "262       263    0.037017    0.000066      Yorkville West         263   \n",
       "\n",
       "       borough   Latitude  Longitude  \n",
       "258      Bronx  40.897932 -73.852215  \n",
       "259     Queens  40.744234 -73.906307  \n",
       "260  Manhattan  40.709139 -74.013023  \n",
       "261  Manhattan  40.775932 -73.946510  \n",
       "262  Manhattan  40.778766 -73.951010  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_location.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_location.to_parquet(TAXI_ZONES_DIR/'taxi_zones_df.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
